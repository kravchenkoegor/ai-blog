import base64
import os
from dotenv import load_dotenv
from glob import glob
from llama_cpp import Llama
from llama_cpp.llama_chat_format import Llava16ChatHandler
from PIL import Image

load_dotenv()

def analyse_image(image_path, model):
  """
  Analyze the given image and return a description using the LLaVA model.

  :param image_path: Path to the image file.
  :return: Description of the image generated by the LLaVA model.
  """

  # Extract the filename and extension from the image path
  filename_with_ext = os.path.basename(image_path)
  filename, ext = os.path.splitext(filename_with_ext)
  
  # Open the image file
  image = Image.open(image_path)

  # Resize the image while maintaining the aspect ratio.
  # Images must have this resolution for LLaVa to work properly 
  image.thumbnail((336, 336))
  
  # Define the path for the resized image and append '_llava' to the original filename
  resized_image_path = os.path.join(
    os.path.dirname(image_path),
    f'{filename}_llava{ext}',  
  )
  
  # Save the resized image to the new path
  image.save(resized_image_path)
  
  # Convert the resized image to base64 format
  with open(resized_image_path, 'rb') as image_llava:
    base64_data = base64.b64encode(image_llava.read()).decode('utf-8')
  
  # Generate a description for the image
  response = model.create_chat_completion(
    # No limit on the number of tokens in the response to make sure response is not truncated
    max_tokens=None,
    messages=[
      {
        'role': 'system',
        'content': 'You are an AI assistant who perfectly describes images.'  # System message to set the assistant's role
      },
      {
        'role': 'user',
        'content': [
          {
            'type': 'text',
            'text': "Describe this image."  # User's request to describe the image
          },
          {
            'type': 'image_url',
            'image_url': f"data:image/png;base64,{base64_data}"  # Base64-encoded image data
          }
        ]
      }
    ]
  )
  
  # Remove temporary image for analysis
  os.remove(resized_image_path)
  
  # Return the content of the description from the response
  return response['choices'][0]['message']['content']

def describe_images_llava(folder_path):
  """
  Process all images in the specified folder and generate descriptions for each image.

  :param folder_path: Path to the folder containing images.
  """

  # Find all images in the specified folder
  images = glob(os.path.join(folder_path, '*.jpg'))
  
  if (len(images) == 0):
    return
  
  # Paths to the CLIP model and the main LLaVA model
  clip_model_path = os.getenv('LLAVA_CLIP_MODEL_PATH')
  model_path = os.getenv('LLAVA_MODEL_PATH')
  
  # Initialize the LLaVA model with specified parameters
  model = Llama(
    model_path=model_path,  # Path to the main model
    chat_handler=Llava16ChatHandler(clip_model_path),  # Handler for integrating CLIP model
    n_ctx=4096,  # Context size for the model
    n_gpu_layers=-1,  # Number of GPU layers; -1 indicates use of all layers
    verbose=False,  # Set verbosity for logging
  )

  for image_path in images:
    # Generate a description for the image
    description = analyse_image(
      image_path=image_path, 
      model=model,
    )
    
    # Append the generated description to a text file
    with open(os.path.join(folder_path, 'description_llava.txt'), 'a') as txt_file:
      txt_file.write(description + '\n')
  
  print(f'Generated descriptions for {len(images)} images')
  